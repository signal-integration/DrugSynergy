---
title: "X+Y analysis using random forests"
output: html_document
---

<br />
#### Simulating mean expression for a given integration profile
<br />
Here we generate numerical values (e_0, e_X, e_Y, e_X+Y) representing a given profile. 


```{r message = FALSE, warning = FALSE}
source("compute_profile_means.R")
source("setPowerPointStyle.R")
setPowerPointStyle()

#reading the profile definitions
PROFCODES = read.table("profile_codes_v2.txt",header = TRUE,sep = "\t") 

#this file encodes the system of equalities/inequalities that we want to solve
load("constraints_vector")

prof_index = 2 #index of the profile we want to simulate
ntimes = 1000 #n. of simulations
exp_min = 2 #min range of expression value
exp_max = 16 #max range of expression value
min_delta = 0.5 #minimum non-zero difference among any two comparisons

profile_means = compute_profile_means(PROFCODES, prof_index, ntimes, 
                                      exp_min, exp_max, 
                                      constraints_vector, min_delta)

colnames(profile_means)=c("0","X","Y","X+Y")
head(profile_means)
```


#### Plotting one example
```{r message = FALSE, warning = FALSE}
source("setPowerPointStyle.R")
setPowerPointStyle()

barplot(profile_means[1,-5], ylab = 'simulated expression')
delta_x = profile_means[1,2] - profile_means[1,1]
delta_y = profile_means[1,3] - profile_means[1,1]
add = profile_means[1,1] + delta_x + delta_y
abline(h = add, col="black")
```


#### Simulating random samples for a given inegration profile
After computing the means for a given profile, we can generate random samples resembling real data. We assume that real data come from normal distributions centered around the means computed above. The standard deviation is passed as a parameter, so it is possible to simulate  arbitrary noise levels.

```{r results='hide', message=FALSE, warning=FALSE}
source("simulate_from_means.R")
source("setPowerPointStyle.R")
setPowerPointStyle()

samples = 4 #number of samples for each condition that will be simulated

signal_to_noise = 3

#noise_level = 0.5 #this means that the signal-to-noise is delta/noise_level = 1/0.5

design = factor(c(rep("CTRL", samples), rep("X", samples), rep("Y", samples), rep("Y+X", samples)))

simulated_values = simulate_from_means(profile_means[1,], samples,
                                       signal_to_noise, exp_min, exp_max)
names(simulated_values) = design

boxplot(simulated_values ~ design, ylab = 'simulated expression', col = 'gray')

#stripchart(simulated_values ~ design, vertical = TRUE, 
#    method = "jitter", add = TRUE, pch = 20, col = 'black',cex #= 1.5)

```





Example with more noise.
```{r results = 'hide', message = FALSE, warning = FALSE}
source("setPowerPointStyle.R")
setPowerPointStyle()

signal_to_noise = 1 #this means that the signal-to-noise is delta/noise_level = 1/1

simulated_values = simulate_from_means(profile_means[1,], samples,
                                       signal_to_noise, exp_min, exp_max)

boxplot(simulated_values ~ design, ylab = 'simulated expression', 
        col = 'gray')

stripchart(simulated_values ~ design, vertical = TRUE, 
    method = "jitter", add = TRUE, pch = 20, col = 'black',cex=1.5)

```


#### Extracting statistical features from a noisy input
Let's assume we have a noisy input in the form of N replicates of 0,X, Y, X+Y. We derive a set of statistical features, which will be used as predictors of the true profile in the  classifier. Such features consist of: the Bliss index, the mean expression values in 0,X, Y, X+Y, and the p-values for all possible pairwise tests. We consider both one-tailed, and two-tailed tests of t-test and Wilkoxon. In total, the are 75 variables. These statistical features are computed with the function *match11* as shown below. 

```{r warning = FALSE}
source("extract_stat_features.R")

profile_features = extract_stat_features(simulated_values, design)
length(profile_features)
head(profile_features, 10)
```


### Analyzing a dataset

```{r warning = FALSE}
#data_file = "GSE75003.txt"
data_file = "tnf_ifn_1_v3"
my_data = read.csv(data_file)
#my_data = read.csv(data_file,sep = '\t')
head(my_data)

```

```{r warning=FALSE}
#graphical parameters
source("setPowerPointStyle.R")
setPowerPointStyle()

expression_data = my_data[,-(1:2)]
expression_data = expression_data[-which(apply(expression_data, 1, sd) == 0), ]

if (max(expression_data)>25) expression_data = log2(expression_data)

my.pca <- prcomp(t(expression_data), center = TRUE, scale = TRUE)

#we assume the same number of samples for each condition
samples = ncol(expression_data)/4

cols = c(rep("black", samples), rep("red", samples),
         rep("blue", samples), rep("yellow", samples))

plot(my.pca$x[, 1], my.pca$x[, 2], col = cols,
     xlab = "PC1", ylab = "PC2", pch = 20, cex = 1.5, main = data_file)

legend("bottomleft", pch = 20, col = unique(cols), 
       legend = c("0","X","Y","X+Y"), bty = 'n',cex = 1)
```




### Applying the classification algorithm
```{r warning = FALSE, message = FALSE}
source("resolve_integration.R")
source("filter_results.R")
source("compute_bliss.R")
#load("classifiers")
#rf_model = classifiers[[3]]

load("rf_model")

PROFCODES = read.table("profile_codes_v2.txt", header = TRUE,sep = "\t") 

#read data file
file_name = "tnf_ifn_1_v3"

combinatorial_data = read.csv(file_name)

samples = ncol(combinatorial_data[,-(1:2)])/4
design = factor(c(rep("CTRL", samples), 
                  rep("X", samples), 
                  rep("Y", samples), 
                  rep("YX", samples)))


results = resolve_integration(combinatorial_data, design, PROFCODES)


#filter results
filtered_results = filter_results(results, adjusted_pval = 0.05)
bliss = apply(filtered_results[[2]], 1, function(x) compute_bliss(x[2:5]))
degs = filtered_results[[1]]
degs$bliss = bliss

save(degs, file = 'IFN_TNF_1h')


#show frequencies of interactions
outcomes = table(filtered_results[[1]]$type)
outcomes = outcomes[c(2,3,1)]


png(file="interactions_barplot.png", width = 200, height = 200)
setPowerPointStyle()
barplot(outcomes, names.arg = c("ant", "syn", "add"), col = c("red", "blue", "gray70"), horiz = T, las = 1,
        xlab = 'gene frequency', xlim = c(0, 780))#, xaxt="n")
text(outcomes[1] + 100, 0.7, outcomes[1])
text(outcomes[2] + 100, 1.9, outcomes[2])
text(outcomes[3] + 100, 3.2, outcomes[3])

dev.off()


#visualize_all_profiles(filtered_results[[1]])

#visualize individual genes
em = filtered_results[[1]][filtered_results[[1]]$prof_index == 54,]

#sort by fc
em = em[order(-em$fc), ]
k = 1
gene_profile = as.numeric(em[k,3:14])
plot(gene_profile ~ design, main = em[k,2], ylab = 'log2(expr)', xlab = '')
stripchart(gene_profile ~ design, vertical = TRUE, 
    method = "jitter", add = TRUE, pch = 20, col = 'black',
    cex = 1.5)



```


```{r warning = FALSE, message = FALSE}

#load("results_1h")

library(eulerr)

venn_df = filtered_results[[2]][,c(18, 19, 21)]

venn_df[venn_df == -1] = 1
names(venn_df) = c("\U0394IFN", "\U0394TNF", "\U0394IFN+TNF")
plot(euler(venn_df), quantities = T)

```


### alluvial plot
```{r warning = FALSE, message = FALSE}
library(reshape2)
source("generate_ocean_plot.R")
deg = filtered_results[[1]]

generate_ocean_plot(deg)

```


#Figure 5
```{r warning = FALSE, message = FALSE}
library(enrichR)
library(ggplot2)
source("cluster_annotation_terms.R")

deg = filtered_results[[1]]
deg$genes = as.character(deg$genes)

all_dbs = listEnrichrDbs()$libraryName

dbs <- all_dbs[c(117, 94, 95, 93)]


joined = cluster_annotation_terms(deg, 'P', dbs, n = 5, p_cut = 0.05)

library(dplyr)
#my_filter = joined$Adjusted.P.value < 0.05 & joined$ratio >= 0.1

joined_f = filter(joined, path_size < 500 & ratio >= 0.02)

joined_f$newadjp = unlist(tapply(joined_f$P.value, joined_f$gene_set, function(x) p.adjust(x, method = 'BH')))

joined_f = filter(joined_f, newadjp < 0.05)


joined_f$split_var = 'a'
joined_f$split_var[joined_f$gene_set == 'all'] = 'b'

ggplot(joined_f, aes(x = gene_set, y = Term)) +geom_point(aes(size = ratio, fill = score), shape = 21) + scale_radius(breaks = seq(0.05, 0.5, by = 0.1), range = c(4,10)) +  scale_fill_gradientn(limits = c(min(joined_f$score),max(joined_f$score)), colours=c("navyblue", "darkmagenta", "darkorange1")) +
theme_bw() + facet_grid(.~split_var, scales = "free_x", space = "free_x", drop = TRUE)+theme(text = element_text(size=12, face = 'bold'), panel.border = element_blank())+theme(panel.spacing = unit(1, "lines"))



#filter and order terms
joined_f$Term = as.factor(joined_f$Term)

selected_terms = levels(joined_f$Term)[c(15,14, 45, 22, 29, 46, 36, 32, 21)]

joined_f_others_s = filter(joined_f, Term %in% selected_terms)

joined_f_others_s$Term = droplevels(joined_f_others_s$Term)

#rename terms
levels(joined_f_others_s$Term)[1] = "Influenza A"
levels(joined_f_others_s$Term)[2] = "IFN-alpha/beta signaling"
levels(joined_f_others_s$Term)[3] = "Metallothioneins"
levels(joined_f_others_s$Term)[4] = "Mineral absorption"
levels(joined_f_others_s$Term)[5] = 'NF-kappa B signaling'
levels(joined_f_others_s$Term)[6] = 'Pos reg of T cell prolif'
levels(joined_f_others_s$Term)[7] = 'Pos reg of NK cell prolif'
levels(joined_f_others_s$Term)[8] = 'TNF signaling'

levels(joined_f_others_s$Term)[9] = 'TLR signaling'



ggplot(joined_f_others_s, aes(x = gene_set, y = Term)) +geom_point(aes(size = ratio, fill = score), shape = 21) + scale_radius(breaks = seq(0.05, 0.5, by = 0.1), range = c(6,11)) +  scale_fill_gradientn(limits = c(min(joined_f_others_s$score), max(joined_f_others_s$score)), colours=c("navyblue", "darkmagenta", "darkorange1")) +
theme_bw() + facet_grid(.~split_var, scales = "free_x", space = "free_x", drop = TRUE)+theme(text = element_text(size=12, face = 'bold'), panel.border = element_blank())+theme(panel.spacing = unit(2, "lines"))+scale_y_discrete(limits = rev(levels(joined_f_others_s$Term)[c(5,2,1,9,7,8,6,4,3)]))





#antagonistic interactions
joined_f$Term = as.factor(joined_f$Term)

selected_terms = levels(joined_f$Term)[c(39,23, 8, 36, 11, 9, 4, 32, 7)]

joined_f_others_s = filter(joined_f, Term %in% selected_terms)

joined_f_others_s$Term = droplevels(joined_f_others_s$Term)


ggplot(joined_f_others_s, aes(x = gene_set, y = Term)) +geom_point(aes(size = ratio, fill = score), shape = 21) + scale_radius(breaks = seq(0.05, 0.5, by = 0.1), range = c(6,9.5)) +  scale_fill_gradientn(limits = c(min(joined_f$score),max(joined_f$score)), colours=c("navyblue", "darkmagenta", "darkorange1")) +
theme_bw() + facet_grid(.~split_var, scales = "free_x", space = "free_x", drop = TRUE)+theme(text = element_text(size=12, face = 'bold'), panel.border = element_blank())+theme(panel.spacing = unit(1, "lines"))+scale_y_discrete(limits = rev(levels(joined_f_others_s$Term)[c(6,3,9,8,5,4,1,7,2)]))



```




```{r warning = FALSE, message = FALSE}
library(enrichR)
library(ggplot2)
source("cluster_annotation_terms.R")


prof_3 = results[[3]][,22]

names_entrez = bitr(names(prof_3), fromType="SYMBOL", toType="ENTREZID", OrgDb="org.Hs.eg.db")

#prof_3_s_GSEA = prof_3_s
#names(prof_3_s_GSEA) = add_entrez$ENTREZID

a = data.frame(prof_3, results[[1]]$genes)
names(a) = c("score", "SYMBOL")
a1 = merge(a, names_entrez, by = 'SYMBOL')

gsea_vector = a1$score
names(gsea_vector) = a1$ENTREZID
gsea_vector = sort(gsea_vector, decreasing = T)


#egmt2 <- GSEA(gsea_vector, TERM2GENE=c5, verbose=FALSE)
#head(egmt2)

ego3 <- gseKEGG(geneList     = gsea_vector,
              #OrgDb        = org.Hs.eg.db,
              #ont          = "BP",
              nPerm        = 1000,
              minGSSize    = 100,
              maxGSSize    = 500,
              pvalueCutoff = 0.95,
              verbose      = FALSE)


entrez = strsplit(ego3@result[5, ]$core_enrichment, '/')[[1]]

bitr(entrez, fromType="ENTREZID", toType="SYMBOL", OrgDb="org.Hs.eg.db")

#MRPS17;MRPL41;MRPS16;MRPS18B;GATC;MRPS2;MRPL14;MRPL46
gene = 'MX1'
values = as.numeric(deg[deg$genes == gene, 3:14])
plot(values ~ design,
     main = gene, ylab = 'log2(expr)', xlab = '')
stripchart(values ~ design, vertical = TRUE, 
    method = "jitter", add = TRUE, pch = 20, col = 'black',cex=1.5)


```
